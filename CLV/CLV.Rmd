---
title: "CLV"
author: "Arnaud Lafont"
date: "5 juin 2018"
runtime: shiny
output: html_document
---

```{r setup, include=FALSE}
# !diagnostics off
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(dplyr)
library(BTYD)

source("../Fonctions_Core_DB.R")
source("~/Documents/Linfo_core.R")

# Informations de connexion à la DB Core
dbname <- Sys.getenv("dbname")
dbhost <- Sys.getenv("dbhost")
dbuser <- Sys.getenv("dbuser")
dbpass <- Sys.getenv("dbpass")

# Liste des équipiers
email_equipier <- c('dumontet.thibaut@gmail.com', 'dumontet.julie@gmail.com', 'laura.h.jalbert@gmail.com', 'rehmvincent@gmail.com', 'a.mechkar@gmail.com', 'helena.luber@gmail.com', 'martin.plancquaert@gmail.com', 'badieresoscar@gmail.com', 'steffina.tagoreraj@gmail.com', 'perono.jeremy@gmail.com', 'roger.virgil@gmail.com', 'boutiermorgane@gmail.com', 'idabmat@gmail.com', 'nadinelhubert@gmail.com', 'faure.remi@yahoo.fr', 'maxime.cisilin@gmail.com', 'voto.arthur@gmail.com')

# Récupération des commandes
req <- "SELECT  o.order_number,
              	o.client_id,
                c.email,
                c.created_at AS client_created_at,
                c.orders_count,
              	o.created_at AS order_created_at,
              	o.total_price_cents AS total_price,
              	SUM(CEILING(li.quantity * li.selling_price_cents/(1+tax_rate))) AS gross_sale,
              	o.pickup,
              	o.discount_code,
                c.first_order_date
  FROM orders o, line_items li, clients c
  WHERE o.id = li.order_id AND o.client_id = c.id
  GROUP BY  o.order_number,
          	o.client_id,
            c.email,
            c.created_at,
            c.orders_count,
          	o.created_at,
          	o.total_price_cents,
          	o.pickup,
          	o.discount_code,
            c.first_order_date
  ORDER BY  order_created_at"
com <- extract_core(req, dbname, dbhost, dbuser, dbpass)

# Correction manuelle :
# Si un client a été créé après le 30 avril 2017 et qu'il n'a pas de date de premiere commande on la trouve
com <- com %>%
  group_by(client_id) %>%
  mutate(first_order_date = as.POSIXct(ifelse(is.na(first_order_date) & client_created_at > as.Date("2017-04-30"), min(order_created_at),first_order_date), origin = "1970-01-01")) %>%
  ungroup() %>%
  # On retire les commandes avec des gross_sale = 0 € car se sont soit des annulations soit des erreurs dans la BD
  filter(gross_sale > 0)

# Création de colonnes
com <- com %>%
  arrange(client_id, order_created_at) %>%
  # calcul du délai entre une commande et la précédente d'un client
  mutate(delai = ifelse(client_id == lag(client_id), round(difftime(order_created_at, lag(order_created_at), units = "days")), NA))%>%
  # nieme = la commande est la combientième du client
  group_by(client_id) %>%
  mutate(nieme = row_number() + orders_count - max(row_number())) %>%
  # derniere : la commande est-elle la dernière du client
  mutate(derniere = ifelse(nieme == orders_count, T, F)) %>%
  ungroup() %>%
  # pas_revu_depuis : Combien de temps s'est-il écoulé depuis que le client n'a pas commandé
  mutate(pas_revu_depuis = ifelse(derniere, round(difftime(now(),order_created_at, units="days")),NA)) %>%
  # Création des colonnes semaine et mois
  mutate(semaine = floor_date(order_created_at, unit = "week", week_start = getOption("lubridate.week.start", 1)),
         mois = floor_date(order_created_at, unit = "month")) %>%
  # Ajout de le cohorte et de l'age lors de la commande
  mutate(cohorte = floor_date(first_order_date, unit = "month"),
         age = round(as.numeric(difftime(order_created_at, cohorte, units = "days"))/30))

# Mise en forme
com <- com %>%
  # La date du jour nous suffit, pas besoin de l'heure
  mutate(client_created_at = as.Date(client_created_at),
         order_created_at = as.Date(order_created_at)) %>%
  # Conversion des centimes en euros
  mutate(gross_sale = gross_sale/100,
         total_price = total_price/100)
  

# Filtres
com <- com %>%
  # On ne garde que les commandes des clients qui ne sont pas des équipiers
  filter(!(email %in% email_equipier) & !(grepl("@deligreens.com$",email))) # %>%
  # Sélection de la plage de date
  # filter(order_created_at > "2017-05-01" & order_created_at < "2018-05-31") %>%
  
```

### Exploration des données
```{r}
df <- com %>%
  group_by(age) %>%
  summarise(panier_moyen = mean(gross_sale))
plot(df$age, df$panier_moyen)
```

```{r}
# Délai entre 2 commandes
q <- quantile(com$delai, probs = c(0.5,seq(0.9,1,0.005)), na.rm = T)
print(q)
```

```{r}
ggplot(mapping = aes(na.omit(com$delai))) +
  stat_ecdf(geom = "step") +
  geom_vline(xintercept = q["99%"], color = "red", size = 0.5) +
  geom_text(aes(x = q["99%"], y = 0.99, label = paste("99 % des délais sont\n inférieurs à",round(q["99%"]), "jours")), color = "red", hjust = -0.02, vjust = 1.1) +
  scale_y_continuous(breaks = seq(0,1,0.1)) +
  scale_x_continuous(breaks = seq(0, max(com$delai, na.rm = T), 20)) +
  ggtitle("Courbe de répartition des délais entre 2 commandes") +
  xlab("X = Délai en jours") +
  ylab("Pourcentage de délais inférieurs à X") +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  theme_bw()
```

```{r}
# fonction : Quand ça fait X jours que les clients n'ont pas commandé, combien sont revenus ?
revenu.apres <- function(df,x){
  return(round(sum(df$revenu[df$duree > x])/nrow(df[df$duree > x,]),3))
}

# Création d'un dataframe : une ligne est un délai entre 2 commandes successives d'un client (revenu = TRUE) ou entre sa derniere commande et aujourd'hui (revenu = FALSE)
df <- data_frame(duree = com$delai[!is.na(com$delai)],
                 revenu = T)
df <- bind_rows(df, data_frame(duree = com$pas_revu_depuis[!is.na(com$pas_revu_depuis)],
                               revenu = F))

x <- 0:max(com$delai, na.rm = T)
y <- sapply(x, revenu.apres, df = df)
coord <- data.frame(x = x, y = y)

pct <- coord$y[coord$x == round(q["99%"])]
jours <- round(q["99%"])
label1 <- c(paste(pct*100, "%"),
          paste(jours, "jours"))
xlabel1 <- c(-13,
           q["99%"])
ylabel1 <- c(pct,
           -0.009)
label2 <- paste0("Seuls ", pct*100, " % des clients qui ont atteint\n", jours, " jours sans commander\nont fini par repasser une commande")
xlabel2 <- jours
ylabel2 <- pct

ggplot() +
  geom_point(data = coord[coord$x >= 15,], aes(x = x, y = y), size = 0.7) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  geom_text(mapping = aes(x = xlabel1, y = ylabel1, label = label1), color = "red") +
  geom_text(mapping = aes(x = xlabel2, y = ylabel2, label = label2), color = "red", vjust = 0, hjust = 0) +
  geom_segment(aes(x = q["99%"], xend = q["99%"], y = 0, yend = coord$y[coord$x == round(q["99%"])]), linetype = "dashed", colour = "red") +
  geom_segment(aes(x = 0, xend = q["99%"], y = coord$y[coord$x == round(q["99%"])], yend = coord$y[coord$x == round(q["99%"])]), linetype = "dashed", colour = "red") +
  scale_y_continuous(breaks = seq(0,1,0.05)) +
  scale_x_continuous(breaks = seq(0, max(com$delai, na.rm = T), 20)) +
  ggtitle("La probabilité qu'un client passe une nouvelle commande selon la date de sa dernière commande") +
  xlab("Nombre de jours sans commande") +
  ylab("Pourcentage des clients qui ont passé une commande après X jours") +
  theme_bw()
```

### Customer Lifetime Value historique

Calculée sur les clients qui ont passé leur première commande dans la seconde moitié de 2017


```{r}
# Calcul de la durée de vie de chaque client
df <- com %>%
  filter(first_order_date >= as.Date("2017-07-01") & first_order_date <= as.Date("2017-12-31")) %>%
  select(client_id, first_order_date, order_created_at, gross_sale) %>%
  group_by(client_id) %>%
  summarise(premiere = floor_date(first(first_order_date), unit = "month"),
            pas_vu_depuis = as.numeric(difftime(Sys.Date(), floor_date(max(order_created_at), unit = "day"), units = "days")),
            actif = pas_vu_depuis < 60,
            derniere = floor_date(max(order_created_at), unit = "month"),
            total = sum(gross_sale),
            nb_com = n()) %>%
  mutate(ddv = round(as.numeric(difftime(derniere, premiere, units = "days"))/30) + 1,
         moy_mois = round(total/ddv, 2))

nb_cli <- nrow(df)
```

`r nb_cli` clients ont effectué leurs premières commandes entre le 1er juillet et le 31 décembre 2017

Quand un client n'a pas commandé depuis 60 jours ou plus, nous n'avons que 25% de chances de le voir revenir.
Nous avons utilisé ce seuil pour déterminer quels sont les clients toujours actifs parmi les `r nb_cli` clients de notre échantillon.

```{r}
df %>%
  group_by(actif) %>%
  summarise(nb_clients = n(),
            pct = round(100*n()/nrow(df),1),
            ddv_moy = round(mean(ddv),1),
            nb_com_moy = round(mean(nb_com),1),
            valeur_cli_moy = round(mean(total),2))
```
```{r}
data <- df$ddv[df$actif]

ggplot(mapping = aes(data)) +
  stat_ecdf(geom = "step") +
  geom_line(aes(x = seq(0:max(data)), y = coord$y[coord$x <= max(data)]))+
  geom_point(aes(x = seq(0:max(data)), y = coord$y[coord$x <= max(data)]))+
  # geom_vline(xintercept = q["99%"], color = "red", size = 0.5) +
  # geom_text(aes(x = q["99%"], y = 0.99, label = paste("99 % des délais sont\n inférieurs à",round(q["99%"]), "jours")), color = "red", hjust = -0.02, vjust = 1.1) +
  scale_y_continuous(breaks = seq(0,1,0.1)) +
  scale_x_continuous(breaks = seq(0, max(data))) +
  ggtitle("Répartition des durées d'absence des clients actifs et les chances de retour") +
  xlab("X = Délai en jours") +
  ylab("Pourcentage") +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  theme_bw()
```

```{r}

```

<!-- ### BG/NBD -->

<!-- #### Préparation des données -->

<!-- ```{r} -->
<!-- beg <- as.Date("2017-05-01") -->
<!-- int <- as.Date("2018-02-20") -->
<!-- end <- as.Date("2018-05-31") -->

<!-- nb.sem.cal <- (1 + as.numeric(int - beg))/7 -->
<!-- nb.sem.holdout <- as.numeric(end - int)/7 -->
<!-- nb.sem.tot <- nb.sem.cal + nb.sem.holdout -->
<!-- ``` -->

<!-- ```{r prep} -->
<!-- # Création de l'event log -->
<!-- elog <- com %>% -->
<!--   filter(first_order_date >= beg & first_order_date <= int) %>% -->
<!--   select(client_id, order_created_at, gross_sale) %>% -->
<!--   filter(order_created_at >= beg & order_created_at <= end) %>% -->
<!--   rename(cust = client_id, -->
<!--          date = order_created_at, -->
<!--          sales = gross_sale) -->

<!-- # # On regroupe les commandes d'un client s'il en a passé plusieurs dans la même journée -->
<!-- # elog <- dc.MergeTransactionsOnSameDate(elog) -->
<!-- #  -->
<!-- # # On sépare notre plage de date en 2 parties : Calibration & Holdout -->
<!-- # end.of.cal.period <- int -->
<!-- # elog.cal <- elog %>% -->
<!-- #   filter(date <= end.of.cal.period) -->
<!-- #  -->
<!-- # # Création de l'event log filtré : sans les clients qui n'ont commandé qu'une fois dans la période -->
<!-- # split.data <- dc.SplitUpElogForRepeatTrans(elog.cal) -->
<!-- # clean.elog <- split.data$repeat.trans.elog -->
<!-- #  -->
<!-- # # Création de la matrice CustomerBytime FILTREE : les clients en ligne, les dates en colonne et les dépenses en valeurs -->
<!-- # # spend.cbt <- dc.CreateSpendCBT(clean.elog) -->
<!-- # freq.cbt <- dc.CreateFreqCBT(clean.elog) -->
<!-- #  -->
<!-- # # Création de la matrive CustomerBytime NON FILTREE -->
<!-- # tot.cbt <- dc.CreateSpendCBT(elog) -->
<!-- #  -->
<!-- # # Merge des 2 matrices -->
<!-- # cal.cbt <- dc.MergeCustomers(tot.cbt, spend.cbt) -->
<!-- #  -->
<!-- # # Création de la matrice CustomerBySufficientStatistic -->
<!-- # birth.periods <- split.data$cust.data$birth.per -->
<!-- # last.dates <- split.data$cust.data$last.date -->
<!-- # cal.cbs.dates <- data.frame(birth.periods, last.dates, end.of.cal.period) -->
<!-- # cal.cbs <- dc.BuildCBSFromCBTAndDates(cal.cbt, cal.cbs.dates, per = "week") -->

<!-- # Paramétrée correctement, la fonction dc.ElogToCbsCbt permet de faire toute cette préparation de données, et même plus. -->
<!-- res <- dc.ElogToCbsCbt(elog, per = "week", T.cal = int, statistic = "total.spend") -->
<!-- cal.cbs <- res$cal$cbs -->
<!-- # hol.cbs <- res$holdout$cbs -->
<!-- ``` -->

<!-- ```{r parametres_pop} -->
<!-- # Première estimation des paramètres relatif à la population -->
<!-- params <- bgnbd.EstimateParameters(cal.cbs) -->
<!-- LL <- bgnbd.cbs.LL(params, cal.cbs) -->

<!-- # Optimisation -->
<!-- p.matrix <- c(params, LL) -->
<!-- for(i in 1:2){ -->
<!--   params <- bgnbd.EstimateParameters(cal.cbs, params) -->
<!--   LL <- bgnbd.cbs.LL(params, cal.cbs) -->
<!--   p.matrix.row <- c(params, LL) -->
<!--   p.matrix <- rbind(p.matrix, p.matrix.row) -->
<!-- } -->
<!-- colnames(p.matrix) <- c("r", "alpha", "a", "b", "LL") -->
<!-- rownames(p.matrix) <- 1:3 -->
<!-- ``` -->

<!-- ```{r transaction_rate} -->
<!-- # Distribution des Transaction Rate -->
<!-- bgnbd.PlotTransactionRateHeterogeneity(params) -->
<!-- ``` -->

<!-- ```{r dropout_rate} -->
<!-- # Distribution des Dropout Rate -->
<!-- bgnbd.PlotDropoutRateHeterogeneity(params) -->
<!-- ``` -->

<!-- ```{r estimations_indiv} -->
<!-- # Estimations individuelles -->

<!-- # Estimation du nombre de commandes d'un client MOYEN en t semaines (semaines car c'est le choix fait plus haut) -->
<!-- # Cette estimation est presque linéaire -->
<!-- bgnbd.Expectation(params, t=5) -->

<!-- # Estimation du nombre de commandes qu'un client SPECIFIQUE passera dans les T.star semaines après la fin de la période de calibration -->
<!-- # client <- "3068" -->
<!-- # cal.cbs[client,] -->
<!-- # bgnbd.ConditionalExpectedTransactions(params, T.star = 52, x = cal.cbs[client,"x"], t.x = cal.cbs[client,"t.x"], T.cal = cal.cbs[client,"T.cal"]) -->
<!-- #  -->
<!-- # # Probabilité qu'un client SPECIFIQUE soit toujours "vivant" à la fin de la période de calibration -->
<!-- # bgnbd.PAlive(params, x = cal.cbs[client,"x"], t.x = cal.cbs[client,"t.x"], T.cal = cal.cbs[client,"T.cal"]) -->
<!-- ``` -->

<!-- ```{r clients_vs_commandes, eval=FALSE, include=FALSE} -->
<!-- # Nombre de client par nombre de commandes, prédictions vs réalité dans la période de calibrage -->
<!-- # Le 3ème paramètre est le nombre de commande à partir duquel les résultats sont agrégés -->
<!-- bgnbd.PlotFrequencyInCalibration(params, cal.cbs, 8) -->
<!-- ``` -->

<!-- ```{r preparation_evaluation} -->
<!-- # Evaluation -->

<!-- # Préparation des données de la période de test (holdout) -->
<!-- elog <- dc.SplitUpElogForRepeatTrans(elog)$repeat.trans.elog -->

<!-- x.star <- rep(0, nrow(cal.cbs)) -->
<!-- cal.cbs <- cbind(cal.cbs, x.star) -->
<!-- elog.custs <- elog$cust -->
<!-- for (i in 1:nrow(cal.cbs)){ -->
<!--   current.cust <- rownames(cal.cbs)[i] -->
<!--   tot.cust.trans <- length(which(elog.custs == current.cust)) -->
<!--   cal.trans <- cal.cbs[i, "x"] -->
<!--   # on retire au nombre de transactions total les transactions effectuées dans la calibration pour n'avoir que cette de la période test -->
<!--   cal.cbs[i, "x.star"] <- tot.cust.trans - cal.trans -->
<!-- } -->
<!-- cal.cbs[1:3,] -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Prédictions vs réalité : -->
<!-- # Nombre de commandes dans la période test selon le nombre de commandes dans l'apprentissage -->

<!-- # Durée de la période de test -->
<!-- T.star <- nb.sem.holdout -->
<!-- censor <- 8 -->
<!-- x.star <- cal.cbs[,"x.star"] -->
<!-- comp <- bgnbd.PlotFreqVsConditionalExpectedFrequency(params, T.star, cal.cbs, x.star, censor) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Prédictions vs réalité : -->
<!-- # Nombre de commandes par semaine -->
<!-- tot.cbt <- dc.CreateFreqCBT(elog) -->
<!-- d.track.data <- rep(0,7*nb.sem.tot) -->
<!-- for (i in colnames(tot.cbt)){ -->
<!--   date.index <- difftime(as.Date(i), beg) + 1 -->
<!--   d.track.data[date.index] <- sum(tot.cbt[,i]) -->
<!-- } -->
<!-- w.track.data <- rep(0, nb.sem.tot) -->
<!-- for (j in 1:nb.sem.tot){ -->
<!--   w.track.data[j] <- sum(d.track.data[(j*7-6):(j*7)]) -->
<!-- } -->

<!-- T.cal <- cal.cbs[, "T.cal"] -->
<!-- inc.tracking <- bgnbd.PlotTrackingInc(params, T.cal, nb.sem.tot, w.track.data, nb.sem.tot) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- cum.tracking.data <- cumsum(w.track.data) -->
<!-- cum.tracking <- bgnbd.PlotTrackingCum(params, T.cal, nb.sem.tot, cum.tracking.data, nb.sem.tot) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- ``` -->

<!-- ```{r, echo=FALSE} -->
<!-- ``` -->

